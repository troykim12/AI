# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kSvBO35Nm3hrPgHMkHAUka5SXen_1SYk
"""

from google.colab import drive
drive.mount('/content/drive')

import os

# ì—¬ê¸°ì— êµ¬ê¸€ ë“œë¼ì´ë¸Œ ìƒì˜ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”
folder_path = '/content/drive/MyDrive/á„Œá…¡á„€á…¡á†¯ train á„†á…µá†¾ test á„‰á…¡á„Œá…µá†«/Test Datasets/test'

# ì´ë¯¸ì§€ í™•ì¥ì ëª©ë¡
image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp')

# ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜ ì„¸ê¸°
image_count = sum(
    1 for filename in os.listdir(folder_path)
    if filename.lower().endswith(image_extensions)
)

print(f"ì´ ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {image_count}")

# import os
# import torch
# import torch.nn as nn
# from torchvision import transforms
# from PIL import Image
# import pandas as pd
# from tqdm import tqdm
# import timm

# # ---------------------------
# # ğŸ”§ ì‚¬ìš©ì ì •ì˜ ê²½ë¡œ ì„¤ì •
# # ---------------------------
# CHECKPOINT_PATH = "/content/drive/MyDrive/ìê°ˆ train ë° test ì‚¬ì§„/best_concatEnsemble_model.pth"
# RESNET_CKPT = "/content/drive/MyDrive/ìê°ˆ train ë° test ì‚¬ì§„/best_model_resnet101.pth"
# DEIT_CKPT = "/content/drive/MyDrive/ìê°ˆ train ë° test ì‚¬ì§„/best_deit_base.pth"
# TEST_CSV = "/content/test/test.csv"
# TEST_DIR = "/content/test/images"
# SUBMISSION_CSV = "/content/ensemble_submission.csv"

# # ---------------------------
# # ğŸ”¤ í´ë˜ìŠ¤ ì´ë¦„ (ì‚¬ì „ìˆœ)
# # ---------------------------
# class_names = [
#     'Andesite',
#     'Basalt',
#     'Etc',
#     'Gneiss',
#     'Granite',
#     'Mud_Sandstone',
#     'Weathered_Rock'
# ]

# NUM_CLASSES = len(class_names)

# # ---------------------------
# # ğŸ§  Feature Extractor Modules
# # ---------------------------
# class ResNetFeatureExtractor(nn.Module):
#     def __init__(self, pretrained_path):
#         super().__init__()
#         from torchvision import models
#         base = models.resnet101(pretrained=False)
#         ckpt = torch.load(pretrained_path, map_location='cpu')
#         ckpt = {k: v for k, v in ckpt.items() if not k.startswith("fc.")}
#         base.load_state_dict(ckpt, strict=False)
#         self.backbone = nn.Sequential(*list(base.children())[:-1])
#         self.out_dim = base.fc.in_features

#     def forward(self, x):
#         x = self.backbone(x)
#         return torch.flatten(x, 1)

# class DeiTFeatureExtractor(nn.Module):
#     def __init__(self, pretrained_path):
#         super().__init__()
#         state_dict = torch.load(pretrained_path, map_location='cpu')
#         filtered = {k: v for k, v in state_dict.items() if not k.startswith("head.")}
#         backbone = timm.create_model('deit_base_patch16_224', pretrained=False, num_classes=0)
#         backbone.load_state_dict(filtered)
#         self.model = backbone
#         self.out_dim = backbone.num_features

#     def forward(self, x):
#         return self.model(x)

# # ---------------------------
# # ğŸ§© ì•™ìƒë¸” ëª¨ë¸
# # ---------------------------
# class ConcatEnsemble(nn.Module):
#     def __init__(self, resnet_ckpt, deit_ckpt):
#         super().__init__()
#         self.resnet = ResNetFeatureExtractor(resnet_ckpt)
#         self.deit = DeiTFeatureExtractor(deit_ckpt)
#         self.classifier = nn.Sequential(
#             nn.Linear(self.resnet.out_dim + self.deit.out_dim, 512),
#             nn.ReLU(),
#             nn.Dropout(0.3),
#             nn.Linear(512, NUM_CLASSES)
#         )

#     def forward(self, x):
#         res_feat = self.resnet(x)
#         deit_feat = self.deit(x)
#         fused = torch.cat((res_feat, deit_feat), dim=1)
#         return self.classifier(fused)

# # ---------------------------
# # âš™ï¸ ëª¨ë¸ ì´ˆê¸°í™” ë° ë¡œë“œ
# # ---------------------------
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model = ConcatEnsemble(RESNET_CKPT, DEIT_CKPT).to(device)

# def rename_state_dict_keys(state_dict, old_prefix, new_prefix):
#     return {k.replace(old_prefix, new_prefix, 1) if k.startswith(old_prefix) else k: v for k, v in state_dict.items()}

# # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ë° í‚¤ ì •ë¦¬
# state_dict = torch.load(CHECKPOINT_PATH, map_location=device)
# state_dict = rename_state_dict_keys(state_dict, "deit.", "deit.model.")
# model.load_state_dict(state_dict, strict=False)
# model.eval()

# # ---------------------------
# # ğŸ–¼ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
# # ---------------------------
# transform = transforms.Compose([
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)
# ])

# # ---------------------------
# # ğŸ” í…ŒìŠ¤íŠ¸ ì¶”ë¡ 
# # ---------------------------
# test_df = pd.read_csv(TEST_CSV)
# image_ids = test_df['ID'].astype(str).tolist()
# preds = []

# for image_id in tqdm(image_ids, desc='ğŸ” Predicting'):
#     img_path = os.path.join(TEST_DIR, f"{image_id}.jpg")
#     if not os.path.exists(img_path):
#         print(f"âš ï¸ Missing: {img_path}")
#         preds.append('Etc')
#         continue

#     image = Image.open(img_path).convert('RGB')
#     image = transform(image).unsqueeze(0).to(device)

#     with torch.no_grad():
#         output = model(image)
#         pred_idx = output.argmax(dim=1).item()
#         preds.append(class_names[pred_idx])

# # ---------------------------
# # ğŸ“„ ê²°ê³¼ ì €ì¥
# # ---------------------------
# submission = pd.DataFrame({
#     'ID': image_ids,
#     'rock_type': preds
# })
# submission.to_csv(SUBMISSION_CSV, index=False)
# print(f"âœ… ì €ì¥ ì™„ë£Œ: {SUBMISSION_CSV}")

from tqdm import tqdm
import torch
from torchvision import transforms
from PIL import Image
import pandas as pd
import os

# 1. ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

import torch
import torch.nn as nn
import timm
from torchvision import models

# ğŸ”¹ Feature Extractor: ResNet101
class ResNetFeatureExtractor(nn.Module):
    def __init__(self, pretrained_path):
        super().__init__()
        base_model = models.resnet101(pretrained=False)
        ckpt = torch.load(pretrained_path, map_location='cpu')
        ckpt = {k: v for k, v in ckpt.items() if not k.startswith("fc.")}
        base_model.load_state_dict(ckpt, strict=False)
        self.backbone = nn.Sequential(*list(base_model.children())[:-1])
        self.out_dim = base_model.fc.in_features

    def forward(self, x):
        x = self.backbone(x)
        return torch.flatten(x, 1)

# ğŸ”¹ Feature Extractor: DeiT
# DeiTFeatureExtractor ìˆ˜ì •
class DeiTFeatureExtractor(nn.Module):
    def __init__(self, pretrained_path):
        super().__init__()
        state_dict = torch.load(pretrained_path, map_location='cpu')
        filtered_state_dict = {k: v for k, v in state_dict.items() if not k.startswith("head.")}
        backbone = timm.create_model('deit_base_patch16_224', pretrained=False, num_classes=0)
        backbone.load_state_dict(filtered_state_dict)
        self.model = backbone
        self.out_dim = backbone.num_features

    def forward(self, x):
        return self.model(x)



# ğŸ”¹ ì•™ìƒë¸” ëª¨ë¸: Concat + Classifier
class ConcatEnsemble(nn.Module):
    def __init__(self, resnet_ckpt_path, deit_ckpt_path, num_classes=7):
        super().__init__()
        self.resnet = ResNetFeatureExtractor(resnet_ckpt_path)
        self.deit = DeiTFeatureExtractor(deit_ckpt_path)
        # ë³€ê²½ëœ DeiT êµ¬ì¡° ë°˜ì˜


        self.classifier = nn.Sequential(
            nn.Linear(self.resnet.out_dim + self.deit.out_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        res_feat = self.resnet(x)
        deit_feat = self.deit(x)
        fused = torch.cat((res_feat, deit_feat), dim=1)
        return self.classifier(fused)


# ğŸ”§ í•„ìš”í•œ ê²½ë¡œ ì •ì˜
resnet_ckpt_path = "/content/drive/MyDrive/ìê°ˆ train ë° test ì‚¬ì§„/best_model_resnet101.pth"
deit_ckpt_path = "/content/drive/MyDrive/ìê°ˆ train ë° test ì‚¬ì§„/best_deit_base.pth"

# âœ… ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì •ìƒ ì¸ì ì „ë‹¬)
model = ConcatEnsemble(
    resnet_ckpt_path=resnet_ckpt_path,
    deit_ckpt_path=deit_ckpt_path
).to(device)

def rename_state_dict_keys(state_dict, old_prefix, new_prefix):
    """state_dict í‚¤ ì´ë¦„ ë°”ê¾¸ëŠ” í•¨ìˆ˜"""
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith(old_prefix):
            new_k = k.replace(old_prefix, new_prefix, 1)
        else:
            new_k = k
        new_state_dict[new_k] = v
    return new_state_dict

# ì›ë˜ ì €ì¥ëœ state_dict ë¶ˆëŸ¬ì˜¤ê¸°
state_dict = torch.load("/content/drive/MyDrive/ìê°ˆ train ë° test ì‚¬ì§„/best_concatEnsemble_model.pth", map_location=device)

# í‚¤ ì´ë¦„ì„ "deit." â†’ "deit.model."ë¡œ ë°”ê¿ˆ
state_dict = rename_state_dict_keys(state_dict, "deit.", "deit.model.")

# ëª¨ë¸ì— ë¡œë“œ (strict=False ê¶Œì¥)
model.load_state_dict(state_dict, strict=False)
model.eval()


# 4. ì „ì²˜ë¦¬ ì •ì˜
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
])

# 5. ì¶”ë¡ 
test_dir = '/content/drive/MyDrive/á„Œá…¡á„€á…¡á†¯ train á„†á…µá†¾ test á„‰á…¡á„Œá…µá†«/Test Datasets/test'
image_paths = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]

class_names = [
    "Andesite",
    "Basalt",
    "Etc",
    "Gneiss",
    "Granite",
    "Mud_sandstone",
    "Weathered_rock"
]

results = []

with torch.no_grad():
    for img_path in tqdm(image_paths, desc="ğŸ” Running Inference"):
        img = Image.open(img_path).convert("RGB")
        input_tensor = transform(img).unsqueeze(0).to(device)

        output = model(input_tensor)
        pred = torch.argmax(output, dim=1).item()
        pred_class = class_names[pred]  # ìˆ«ìë¥¼ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ë³€í™˜

        results.append({
            "ID": os.path.basename(img_path),
            "rock_type": pred_class
        })


# 6. CSV ì €ì¥
df = pd.DataFrame(results)
df.to_csv("/content/drive/MyDrive/á„Œá…¡á„€á…¡á†¯ train á„†á…µá†¾ test á„‰á…¡á„Œá…µá†«/predictions.csv", index=False)
print("âœ… ì¶”ë¡  ì™„ë£Œ: predictions.csv ì €ì¥ë¨")