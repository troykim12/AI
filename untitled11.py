# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kSvBO35Nm3hrPgHMkHAUka5SXen_1SYk
"""

from google.colab import drive
drive.mount('/content/drive')

import os

# 여기에 구글 드라이브 상의 폴더 경로를 입력하세요
folder_path = '/content/drive/MyDrive/자갈 train 및 test 사진/Test Datasets/test'

# 이미지 확장자 목록
image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp')

# 이미지 파일 개수 세기
image_count = sum(
    1 for filename in os.listdir(folder_path)
    if filename.lower().endswith(image_extensions)
)

print(f"총 이미지 파일 개수: {image_count}")

# import os
# import torch
# import torch.nn as nn
# from torchvision import transforms
# from PIL import Image
# import pandas as pd
# from tqdm import tqdm
# import timm

# # ---------------------------
# # 🔧 사용자 정의 경로 설정
# # ---------------------------
# CHECKPOINT_PATH = "/content/drive/MyDrive/자갈 train 및 test 사진/best_concatEnsemble_model.pth"
# RESNET_CKPT = "/content/drive/MyDrive/자갈 train 및 test 사진/best_model_resnet101.pth"
# DEIT_CKPT = "/content/drive/MyDrive/자갈 train 및 test 사진/best_deit_base.pth"
# TEST_CSV = "/content/test/test.csv"
# TEST_DIR = "/content/test/images"
# SUBMISSION_CSV = "/content/ensemble_submission.csv"

# # ---------------------------
# # 🔤 클래스 이름 (사전순)
# # ---------------------------
# class_names = [
#     'Andesite',
#     'Basalt',
#     'Etc',
#     'Gneiss',
#     'Granite',
#     'Mud_Sandstone',
#     'Weathered_Rock'
# ]

# NUM_CLASSES = len(class_names)

# # ---------------------------
# # 🧠 Feature Extractor Modules
# # ---------------------------
# class ResNetFeatureExtractor(nn.Module):
#     def __init__(self, pretrained_path):
#         super().__init__()
#         from torchvision import models
#         base = models.resnet101(pretrained=False)
#         ckpt = torch.load(pretrained_path, map_location='cpu')
#         ckpt = {k: v for k, v in ckpt.items() if not k.startswith("fc.")}
#         base.load_state_dict(ckpt, strict=False)
#         self.backbone = nn.Sequential(*list(base.children())[:-1])
#         self.out_dim = base.fc.in_features

#     def forward(self, x):
#         x = self.backbone(x)
#         return torch.flatten(x, 1)

# class DeiTFeatureExtractor(nn.Module):
#     def __init__(self, pretrained_path):
#         super().__init__()
#         state_dict = torch.load(pretrained_path, map_location='cpu')
#         filtered = {k: v for k, v in state_dict.items() if not k.startswith("head.")}
#         backbone = timm.create_model('deit_base_patch16_224', pretrained=False, num_classes=0)
#         backbone.load_state_dict(filtered)
#         self.model = backbone
#         self.out_dim = backbone.num_features

#     def forward(self, x):
#         return self.model(x)

# # ---------------------------
# # 🧩 앙상블 모델
# # ---------------------------
# class ConcatEnsemble(nn.Module):
#     def __init__(self, resnet_ckpt, deit_ckpt):
#         super().__init__()
#         self.resnet = ResNetFeatureExtractor(resnet_ckpt)
#         self.deit = DeiTFeatureExtractor(deit_ckpt)
#         self.classifier = nn.Sequential(
#             nn.Linear(self.resnet.out_dim + self.deit.out_dim, 512),
#             nn.ReLU(),
#             nn.Dropout(0.3),
#             nn.Linear(512, NUM_CLASSES)
#         )

#     def forward(self, x):
#         res_feat = self.resnet(x)
#         deit_feat = self.deit(x)
#         fused = torch.cat((res_feat, deit_feat), dim=1)
#         return self.classifier(fused)

# # ---------------------------
# # ⚙️ 모델 초기화 및 로드
# # ---------------------------
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model = ConcatEnsemble(RESNET_CKPT, DEIT_CKPT).to(device)

# def rename_state_dict_keys(state_dict, old_prefix, new_prefix):
#     return {k.replace(old_prefix, new_prefix, 1) if k.startswith(old_prefix) else k: v for k, v in state_dict.items()}

# # 체크포인트 로드 및 키 정리
# state_dict = torch.load(CHECKPOINT_PATH, map_location=device)
# state_dict = rename_state_dict_keys(state_dict, "deit.", "deit.model.")
# model.load_state_dict(state_dict, strict=False)
# model.eval()

# # ---------------------------
# # 🖼️ 이미지 전처리
# # ---------------------------
# transform = transforms.Compose([
#     transforms.Resize((224, 224)),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)
# ])

# # ---------------------------
# # 🔍 테스트 추론
# # ---------------------------
# test_df = pd.read_csv(TEST_CSV)
# image_ids = test_df['ID'].astype(str).tolist()
# preds = []

# for image_id in tqdm(image_ids, desc='🔍 Predicting'):
#     img_path = os.path.join(TEST_DIR, f"{image_id}.jpg")
#     if not os.path.exists(img_path):
#         print(f"⚠️ Missing: {img_path}")
#         preds.append('Etc')
#         continue

#     image = Image.open(img_path).convert('RGB')
#     image = transform(image).unsqueeze(0).to(device)

#     with torch.no_grad():
#         output = model(image)
#         pred_idx = output.argmax(dim=1).item()
#         preds.append(class_names[pred_idx])

# # ---------------------------
# # 📄 결과 저장
# # ---------------------------
# submission = pd.DataFrame({
#     'ID': image_ids,
#     'rock_type': preds
# })
# submission.to_csv(SUBMISSION_CSV, index=False)
# print(f"✅ 저장 완료: {SUBMISSION_CSV}")

from tqdm import tqdm
import torch
from torchvision import transforms
from PIL import Image
import pandas as pd
import os

# 1. 디바이스 설정
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

import torch
import torch.nn as nn
import timm
from torchvision import models

# 🔹 Feature Extractor: ResNet101
class ResNetFeatureExtractor(nn.Module):
    def __init__(self, pretrained_path):
        super().__init__()
        base_model = models.resnet101(pretrained=False)
        ckpt = torch.load(pretrained_path, map_location='cpu')
        ckpt = {k: v for k, v in ckpt.items() if not k.startswith("fc.")}
        base_model.load_state_dict(ckpt, strict=False)
        self.backbone = nn.Sequential(*list(base_model.children())[:-1])
        self.out_dim = base_model.fc.in_features

    def forward(self, x):
        x = self.backbone(x)
        return torch.flatten(x, 1)

# 🔹 Feature Extractor: DeiT
# DeiTFeatureExtractor 수정
class DeiTFeatureExtractor(nn.Module):
    def __init__(self, pretrained_path):
        super().__init__()
        state_dict = torch.load(pretrained_path, map_location='cpu')
        filtered_state_dict = {k: v for k, v in state_dict.items() if not k.startswith("head.")}
        backbone = timm.create_model('deit_base_patch16_224', pretrained=False, num_classes=0)
        backbone.load_state_dict(filtered_state_dict)
        self.model = backbone
        self.out_dim = backbone.num_features

    def forward(self, x):
        return self.model(x)



# 🔹 앙상블 모델: Concat + Classifier
class ConcatEnsemble(nn.Module):
    def __init__(self, resnet_ckpt_path, deit_ckpt_path, num_classes=7):
        super().__init__()
        self.resnet = ResNetFeatureExtractor(resnet_ckpt_path)
        self.deit = DeiTFeatureExtractor(deit_ckpt_path)
        # 변경된 DeiT 구조 반영


        self.classifier = nn.Sequential(
            nn.Linear(self.resnet.out_dim + self.deit.out_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        res_feat = self.resnet(x)
        deit_feat = self.deit(x)
        fused = torch.cat((res_feat, deit_feat), dim=1)
        return self.classifier(fused)


# 🔧 필요한 경로 정의
resnet_ckpt_path = "/content/drive/MyDrive/자갈 train 및 test 사진/best_model_resnet101.pth"
deit_ckpt_path = "/content/drive/MyDrive/자갈 train 및 test 사진/best_deit_base.pth"

# ✅ 모델 인스턴스 생성 (정상 인자 전달)
model = ConcatEnsemble(
    resnet_ckpt_path=resnet_ckpt_path,
    deit_ckpt_path=deit_ckpt_path
).to(device)

def rename_state_dict_keys(state_dict, old_prefix, new_prefix):
    """state_dict 키 이름 바꾸는 함수"""
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith(old_prefix):
            new_k = k.replace(old_prefix, new_prefix, 1)
        else:
            new_k = k
        new_state_dict[new_k] = v
    return new_state_dict

# 원래 저장된 state_dict 불러오기
state_dict = torch.load("/content/drive/MyDrive/자갈 train 및 test 사진/best_concatEnsemble_model.pth", map_location=device)

# 키 이름을 "deit." → "deit.model."로 바꿈
state_dict = rename_state_dict_keys(state_dict, "deit.", "deit.model.")

# 모델에 로드 (strict=False 권장)
model.load_state_dict(state_dict, strict=False)
model.eval()


# 4. 전처리 정의
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
])

# 5. 추론
test_dir = '/content/drive/MyDrive/자갈 train 및 test 사진/Test Datasets/test'
image_paths = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]

class_names = [
    "Andesite",
    "Basalt",
    "Etc",
    "Gneiss",
    "Granite",
    "Mud_sandstone",
    "Weathered_rock"
]

results = []

with torch.no_grad():
    for img_path in tqdm(image_paths, desc="🔍 Running Inference"):
        img = Image.open(img_path).convert("RGB")
        input_tensor = transform(img).unsqueeze(0).to(device)

        output = model(input_tensor)
        pred = torch.argmax(output, dim=1).item()
        pred_class = class_names[pred]  # 숫자를 클래스명으로 변환

        results.append({
            "ID": os.path.basename(img_path),
            "rock_type": pred_class
        })


# 6. CSV 저장
df = pd.DataFrame(results)
df.to_csv("/content/drive/MyDrive/자갈 train 및 test 사진/predictions.csv", index=False)
print("✅ 추론 완료: predictions.csv 저장됨")